{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset and preprocess\n",
    "pivot_df = pd.read_csv(\"synthetic_scenario_30_nodes.csv\")\n",
    "pivot_df = pivot_df.apply(lambda x: x.fillna(x.mean()), axis=0)  # Fill missing values\n",
    "pivot_df = pivot_df.head(10000)  # Restrict to first 20000 time steps\n",
    "\n",
    "# Parameters\n",
    "reward = 0.5\n",
    "theta = 0.5  # Threshold for reward condition\n",
    "penalty = -0.5  # Penalty for polling when difference is <= theta\n",
    "initial_value = 20  # Initial estimate for last polled values\n",
    "\n",
    "# Set parameters\n",
    "beta_1 = 0.8  # dEWMA parameter for state value\n",
    "beta_2 = 0.01  # dEWMA parameter for rate of change\n",
    "\n",
    "# Extract column names, ensuring \"SN\" is excluded\n",
    "columns = [col for col in pivot_df.columns if col != \"SN\"]\n",
    "num_nodes = len(columns)  # Number of sensor nodes based on dataset columns\n",
    "num_time_steps = len(pivot_df)  # Total time steps based on dataset length\n",
    "\n",
    "# Function to calculate Age of Incorrect Information (AoII) at the sink\n",
    "def calculate_aoii_sink(current_time, last_received_time, last_rate_of_change):\n",
    "    # Handle potential NaN or Inf values\n",
    "    time_diff = current_time - last_received_time\n",
    "    if np.isnan(last_rate_of_change) or np.isinf(last_rate_of_change):\n",
    "        return 0.0  # Default to zero if rate of change is invalid\n",
    "    return abs(time_diff * last_rate_of_change)\n",
    "\n",
    "# Helper function to update state using dEWMA\n",
    "def update_node_state_dewma(measured_value, last_state_value, last_rate_of_change, delta_t, beta_1, beta_2):\n",
    "    # Handle the case where delta_t is 0 to avoid division by zero\n",
    "    if delta_t == 0:\n",
    "        return measured_value, last_rate_of_change  # Return measured value and keep the last rate of change\n",
    "    \n",
    "    x1 = beta_1 * measured_value + (1 - beta_1) * (last_state_value + last_rate_of_change * delta_t)\n",
    "    x2 = beta_2 * (x1 - last_state_value) / delta_t + (1 - beta_2) * last_rate_of_change\n",
    "    return x1, x2\n",
    "\n",
    "# Function to extract numeric node ID from column names dynamically, ensuring valid extraction\n",
    "def extract_node_id(col_name):\n",
    "    \"\"\"Extract numeric node ID from column name, handling cases where no digits are found.\"\"\"\n",
    "    digits = ''.join(filter(str.isdigit, col_name))\n",
    "    return int(digits) if digits else None  # Return None if no digits are found\n",
    "\n",
    "# Dynamic Penalty Update algorithm based on Whittle indices\n",
    "def dynamic_penalty_update(whittle_indices, M, current_lambda):\n",
    "    # Convert dictionary values to a list of whittle indices, handling any NaN values\n",
    "    c_values = []\n",
    "    for v in whittle_indices.values():\n",
    "        if np.isnan(v):\n",
    "            c_values.append(-float('inf'))  # Treat NaN as negative infinity (won't be polled)\n",
    "        else:\n",
    "            c_values.append(v)\n",
    "    \n",
    "    # Identify the set ℰ of nodes where c_i > λ(t)\n",
    "    eligible_nodes = [i for i, c_i in enumerate(c_values) if c_i > current_lambda]\n",
    "    \n",
    "    # If |ℰ| ≤ M, no penalty update needed\n",
    "    if len(eligible_nodes) <= M:\n",
    "        return current_lambda\n",
    "    \n",
    "    # Sort the c_i values in descending order\n",
    "    sorted_c_values = sorted(c_values, reverse=True)\n",
    "    \n",
    "    # Identify the M-th value\n",
    "    M_th_value = sorted_c_values[M-1]\n",
    "    \n",
    "    # Update penalty to the M-th value\n",
    "    new_lambda = M_th_value\n",
    "    \n",
    "    return new_lambda\n",
    "\n",
    "# Main function to simulate Whittle AoII with rewards and track transmission counts\n",
    "def run_simulation_whittle_aoii_dynamic_penalty(pivot_df, columns, M, theta, penalty):\n",
    "    # Track the number of times each category is pulled\n",
    "    category_counts = {'Category A': 0, 'Category B': 0, 'Category C': 0}\n",
    "    total_polls = 0  # Track total number of polls across all nodes\n",
    "    last_update_times = {col: 0 for col in columns}  # Last update time for each node\n",
    "    state_node = {col: np.array([20.0, 0.1]) for col in columns}  # Node states\n",
    "    \n",
    "    # Initialize dynamic penalty (λ) to 0\n",
    "    aoii_penalty = 0.0\n",
    "    \n",
    "    # Track penalty evolution\n",
    "    penalty_values = [aoii_penalty]\n",
    "    \n",
    "    # Track nodes polled at each time step\n",
    "    nodes_polled_count = []\n",
    "    \n",
    "    # Set minimum timestamp difference to avoid division by zero\n",
    "    min_delta_t = 1  # Minimum time difference of 1 to avoid division by zero\n",
    "    \n",
    "    # Track estimated values and MSE\n",
    "    estimated_values = {col: np.zeros(len(pivot_df)) for col in columns}\n",
    "    mse_per_timestep = []\n",
    "    \n",
    "    # Initialize estimated values with initial state\n",
    "    for col in columns:\n",
    "        estimated_values[col][0] = state_node[col][0]\n",
    "\n",
    "    for t in range(len(pivot_df)):\n",
    "        # Step 1: Compute Whittle indices for each node based on AoII\n",
    "        whittle_indices = {}\n",
    "        for col in columns:\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "            measured_value = pivot_df.loc[t, col]\n",
    "\n",
    "            # Correct AoII calculation at the sink using rate of change\n",
    "            current_aoii = calculate_aoii_sink(t, last_update_times[col], last_rate_of_change)\n",
    "            future_aoii_passive = calculate_aoii_sink(t+1, last_update_times[col], last_rate_of_change)\n",
    "            future_aoii_active = 0  # AoII resets to 0 if polled\n",
    "\n",
    "            # Whittle index calculations - with safety checks for NaN/Inf values\n",
    "            q_passive = current_aoii + future_aoii_passive\n",
    "            q_active = current_aoii + future_aoii_active + aoii_penalty\n",
    "            \n",
    "            # Calculate the Whittle index with safeguards against invalid values\n",
    "            whittle_index = q_passive - q_active\n",
    "            \n",
    "            # Handle NaN or Inf values\n",
    "            if np.isnan(whittle_index) or np.isinf(whittle_index):\n",
    "                whittle_indices[col] = -float('inf')  # Set to negative infinity if invalid\n",
    "            else:\n",
    "                whittle_indices[col] = whittle_index\n",
    "\n",
    "        # Step 2: Update the dynamic penalty (λ) using the algorithm\n",
    "        aoii_penalty = dynamic_penalty_update(whittle_indices, M, aoii_penalty)\n",
    "        penalty_values.append(aoii_penalty)\n",
    "        \n",
    "        # Step 3: Select nodes to poll based on the updated penalty\n",
    "        nodes_to_poll = [col for col in whittle_indices if whittle_indices[col] >= aoii_penalty]\n",
    "        nodes_polled_count.append(len(nodes_to_poll))\n",
    "        total_polls += len(nodes_to_poll)  # Update total polls count\n",
    "\n",
    "        # Step 4: Poll selected nodes and calculate rewards\n",
    "        for col in nodes_to_poll:\n",
    "            measured_value = pivot_df.loc[t, col]\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "\n",
    "            delta_t_dynamic = max(min_delta_t, t - last_update_times[col])  # Time since last update (ensure at least 1)\n",
    "\n",
    "            # Update node state and last update time\n",
    "            state_node[col] = update_node_state_dewma(\n",
    "                measured_value, last_state_value, last_rate_of_change, delta_t_dynamic, beta_1=beta_1, beta_2=beta_2\n",
    "            )\n",
    "            last_update_times[col] = t\n",
    "\n",
    "            # Extract node ID dynamically and categorize\n",
    "            node_id = extract_node_id(col)\n",
    "            if node_id is not None:\n",
    "                if 1 <= node_id <= 10:\n",
    "                    category_counts['Category A'] += 1\n",
    "                elif 11 <= node_id <= 20:\n",
    "                    category_counts['Category B'] += 1\n",
    "                elif 21 <= node_id <= 30:\n",
    "                    category_counts['Category C'] += 1\n",
    "        \n",
    "        # Step 5: Update estimated values for all nodes (polled and non-polled)\n",
    "        for col in columns:\n",
    "            if col in nodes_to_poll:\n",
    "                # For polled nodes, use the actual measurement\n",
    "                estimated_values[col][t] = float(pivot_df.loc[t, col])\n",
    "            else:\n",
    "                # For non-polled nodes, use the predicted value from the state model\n",
    "                last_state_value, last_rate_of_change = state_node[col]\n",
    "                delta_t_since_last = max(min_delta_t, t - last_update_times[col])\n",
    "                # Predict using the linear model: x(t) = x(t-1) + rate * delta_t\n",
    "                estimated_values[col][t] = last_state_value + last_rate_of_change * delta_t_since_last\n",
    "        \n",
    "    \n",
    "    # Calculate MAE manually since we already have the estimated values\n",
    "    total_abs_error = 0\n",
    "    count = 0\n",
    "    for t in range(len(pivot_df)):\n",
    "        for col in columns:\n",
    "            total_abs_error += abs(pivot_df.loc[t, col] - estimated_values[col][t])\n",
    "            count += 1\n",
    "    avg_mae = total_abs_error / count\n",
    "\n",
    "    return {\n",
    "        'total_polls': total_polls,\n",
    "        'category_counts': category_counts,\n",
    "        'avg_mse': avg_mse,\n",
    "        'avg_rmse': avg_rmse,\n",
    "        'avg_mae': avg_mae\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Average AoII: 2.8568904221083122\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset and preprocess\n",
    "pivot_df = pd.read_csv(\"synthetic_scenario_30_nodes.csv\")\n",
    "pivot_df = pivot_df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "pivot_df = pivot_df.head(10000)\n",
    "\n",
    "reward = 0.5\n",
    "theta = 0.5\n",
    "penalty = -0.5\n",
    "initial_value = 20\n",
    "beta_1 = 0.8\n",
    "beta_2 = 0.01\n",
    "\n",
    "columns = [col for col in pivot_df.columns if col != \"SN\"]\n",
    "num_nodes = len(columns)\n",
    "num_time_steps = len(pivot_df)\n",
    "\n",
    "def calculate_aoii_sink(current_time, last_received_time, last_rate_of_change):\n",
    "    time_diff = current_time - last_received_time\n",
    "    if np.isnan(last_rate_of_change) or np.isinf(last_rate_of_change):\n",
    "        return 0.0\n",
    "    return abs(time_diff * last_rate_of_change)\n",
    "\n",
    "def update_node_state_dewma(measured_value, last_state_value, last_rate_of_change, delta_t, beta_1, beta_2):\n",
    "    if delta_t == 0:\n",
    "        return measured_value, last_rate_of_change\n",
    "    x1 = beta_1 * measured_value + (1 - beta_1) * (last_state_value + last_rate_of_change * delta_t)\n",
    "    x2 = beta_2 * (x1 - last_state_value) / delta_t + (1 - beta_2) * last_rate_of_change\n",
    "    return x1, x2\n",
    "\n",
    "def extract_node_id(col_name):\n",
    "    digits = ''.join(filter(str.isdigit, col_name))\n",
    "    return int(digits) if digits else None\n",
    "\n",
    "def dynamic_penalty_update(whittle_indices, M, current_lambda):\n",
    "    c_values = [v if not np.isnan(v) else -float('inf') for v in whittle_indices.values()]\n",
    "    eligible_nodes = [i for i, c_i in enumerate(c_values) if c_i > current_lambda]\n",
    "    if len(eligible_nodes) <= M:\n",
    "        return current_lambda\n",
    "    sorted_c_values = sorted(c_values, reverse=True)\n",
    "    M_th_value = sorted_c_values[M - 1]\n",
    "    return M_th_value\n",
    "\n",
    "def run_simulation_with_aoii_tracking(pivot_df, columns, M, theta, penalty):\n",
    "    last_update_times = {col: 0 for col in columns}\n",
    "    state_node = {col: np.array([20.0, 0.1]) for col in columns}\n",
    "    aoii_penalty = 0.0\n",
    "    min_delta_t = 1\n",
    "\n",
    "    # Track AoII growth over time for each node\n",
    "    cumulative_aoii_per_node = {col: 0.0 for col in columns}\n",
    "\n",
    "    for t in range(len(pivot_df)):\n",
    "        whittle_indices = {}\n",
    "        for col in columns:\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "            current_aoii = calculate_aoii_sink(t, last_update_times[col], last_rate_of_change)\n",
    "            future_aoii_passive = calculate_aoii_sink(t + 1, last_update_times[col], last_rate_of_change)\n",
    "            q_passive = current_aoii + future_aoii_passive\n",
    "            q_active = current_aoii + 0 + aoii_penalty\n",
    "            whittle_index = q_passive - q_active\n",
    "            whittle_indices[col] = whittle_index if not (np.isnan(whittle_index) or np.isinf(whittle_index)) else -float('inf')\n",
    "\n",
    "        aoii_penalty = dynamic_penalty_update(whittle_indices, M, aoii_penalty)\n",
    "\n",
    "        nodes_to_poll = [col for col in whittle_indices if whittle_indices[col] >= aoii_penalty]\n",
    "\n",
    "        for col in columns:\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "            current_aoii = calculate_aoii_sink(t, last_update_times[col], last_rate_of_change)\n",
    "\n",
    "            # Add current AoII to cumulative count\n",
    "            cumulative_aoii_per_node[col] += current_aoii\n",
    "\n",
    "            if col in nodes_to_poll:\n",
    "                measured_value = pivot_df.loc[t, col]\n",
    "                delta_t_dynamic = max(min_delta_t, t - last_update_times[col])\n",
    "                state_node[col] = update_node_state_dewma(\n",
    "                    measured_value, last_state_value, last_rate_of_change, delta_t_dynamic, beta_1, beta_2\n",
    "                )\n",
    "                last_update_times[col] = t\n",
    "\n",
    "    average_aoii_per_node = {col: cumulative_aoii_per_node[col] / num_time_steps for col in columns}\n",
    "    overall_average_aoii = sum(average_aoii_per_node.values()) / len(columns)\n",
    "\n",
    "    return average_aoii_per_node, overall_average_aoii\n",
    "\n",
    "average_aoii_per_node, overall_average_aoii = run_simulation_with_aoii_tracking(pivot_df, columns, M=2, theta=0.5, penalty=-0.5)\n",
    "print(\"Overall Average AoII:\", overall_average_aoii)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Average AoII (Whittle with Global Penalty): 0.5904328278486236\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset and preprocess\n",
    "#pivot_df = pd.read_csv(\"synthetic_scenario_30_nodes.csv\")\n",
    "pivot_df = pd.read_csv(\"simulated_office_environment.csv\")\n",
    "pivot_df = pivot_df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "pivot_df = pivot_df.head(10000)\n",
    "\n",
    "initial_value = 20\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.01\n",
    "columns = [col for col in pivot_df.columns if col != \"SN\"]\n",
    "num_nodes = len(columns)\n",
    "num_time_steps = len(pivot_df)\n",
    "\n",
    "def calculate_aoii_sink(current_time, last_received_time, last_rate_of_change):\n",
    "    return abs((current_time - last_received_time) * last_rate_of_change)\n",
    "\n",
    "def update_node_state_dewma(measured_value, last_state_value, last_rate_of_change, delta_t, beta_1, beta_2):\n",
    "    if delta_t == 0:\n",
    "        return measured_value, last_rate_of_change\n",
    "    x1 = beta_1 * measured_value + (1 - beta_1) * (last_state_value + last_rate_of_change * delta_t)\n",
    "    x2 = beta_2 * (x1 - last_state_value) / delta_t + (1 - beta_2) * last_rate_of_change\n",
    "    return x1, x2\n",
    "\n",
    "def run_simulation_whittle_aoii_with_global_penalty(pivot_df, columns, M, theta, penalty, global_aoii_penalty):\n",
    "    last_update_times = {col: 0 for col in columns}\n",
    "    state_node = {col: np.array([20.0, 0.1]) for col in columns}\n",
    "    cumulative_aoii_per_node = {col: 0.0 for col in columns}\n",
    "    min_delta_t = 1\n",
    "\n",
    "    for t in range(len(pivot_df)):\n",
    "        whittle_indices = {}\n",
    "        for col in columns:\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "            current_aoii = calculate_aoii_sink(t, last_update_times[col], last_rate_of_change)\n",
    "            future_aoii_passive = calculate_aoii_sink(t + 1, last_update_times[col], last_rate_of_change)\n",
    "            q_passive = current_aoii + future_aoii_passive\n",
    "            q_active = current_aoii + 0 + global_aoii_penalty\n",
    "            whittle_indices[col] = q_passive - q_active\n",
    "\n",
    "            cumulative_aoii_per_node[col] += current_aoii\n",
    "\n",
    "        nodes_to_poll = [col for col in whittle_indices if whittle_indices[col] >= 0]\n",
    "        if len(nodes_to_poll) > M:\n",
    "            nodes_to_poll = sorted(nodes_to_poll, key=whittle_indices.get, reverse=True)[:M]\n",
    "\n",
    "        for col in nodes_to_poll:\n",
    "            measured_value = pivot_df.loc[t, col]\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "            delta_t_dynamic = max(min_delta_t, t - last_update_times[col])\n",
    "            state_node[col] = update_node_state_dewma(\n",
    "                measured_value, last_state_value, last_rate_of_change, delta_t_dynamic, beta_1, beta_2\n",
    "            )\n",
    "            last_update_times[col] = t\n",
    "\n",
    "    average_aoii_per_node = {col: cumulative_aoii_per_node[col] / num_time_steps for col in columns}\n",
    "    overall_average_aoii = sum(average_aoii_per_node.values()) / len(columns)\n",
    "\n",
    "    return average_aoii_per_node, overall_average_aoii\n",
    "\n",
    "M = 1\n",
    "theta = 0.5\n",
    "penalty = -0.5\n",
    "global_aoii_penalty = 0\n",
    "\n",
    "average_aoii_per_node, overall_average_aoii = run_simulation_whittle_aoii_with_global_penalty(\n",
    "    pivot_df, columns, M, theta, penalty, global_aoii_penalty\n",
    ")\n",
    "print(\"Overall Average AoII (Whittle with Global Penalty):\", overall_average_aoii)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Average AoII (Round Robin): 0.7376180618005805\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset and preprocess\n",
    "#pivot_df = pd.read_csv(\"synthetic_scenario_30_nodes.csv\")\n",
    "pivot_df = pd.read_csv(\"simulated_office_environment.csv\")\n",
    "pivot_df = pivot_df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "pivot_df = pivot_df.head(10000)\n",
    "\n",
    "initial_value = 20\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.01\n",
    "\n",
    "columns = [col for col in pivot_df.columns if col != \"SN\"]\n",
    "num_nodes = len(columns)\n",
    "num_time_steps = len(pivot_df)\n",
    "\n",
    "def calculate_aoii_sink(current_time, last_received_time, last_rate_of_change):\n",
    "    time_diff = current_time - last_received_time\n",
    "    if np.isnan(last_rate_of_change) or np.isinf(last_rate_of_change):\n",
    "        return 0.0\n",
    "    return abs(time_diff * last_rate_of_change)\n",
    "\n",
    "def update_node_state_dewma(measured_value, last_state_value, last_rate_of_change, delta_t, beta_1, beta_2):\n",
    "    if delta_t == 0:\n",
    "        return measured_value, last_rate_of_change\n",
    "    x1 = beta_1 * measured_value + (1 - beta_1) * (last_state_value + last_rate_of_change * delta_t)\n",
    "    x2 = beta_2 * (x1 - last_state_value) / delta_t + (1 - beta_2) * last_rate_of_change\n",
    "    return x1, x2\n",
    "\n",
    "def run_simulation_round_robin_aoii_tracking(pivot_df, columns):\n",
    "    last_update_times = {col: 0 for col in columns}\n",
    "    state_node = {col: np.array([20.0, 0.1]) for col in columns}\n",
    "    min_delta_t = 1\n",
    "\n",
    "    cumulative_aoii_per_node = {col: 0.0 for col in columns}\n",
    "\n",
    "    # Round-robin polling index\n",
    "    polling_index = 0\n",
    "\n",
    "    for t in range(len(pivot_df)):\n",
    "        current_node = columns[polling_index % len(columns)]\n",
    "\n",
    "        for col in columns:\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "            current_aoii = calculate_aoii_sink(t, last_update_times[col], last_rate_of_change)\n",
    "            cumulative_aoii_per_node[col] += current_aoii\n",
    "\n",
    "            if col == current_node:\n",
    "                measured_value = pivot_df.loc[t, col]\n",
    "                delta_t_dynamic = max(min_delta_t, t - last_update_times[col])\n",
    "                state_node[col] = update_node_state_dewma(\n",
    "                    measured_value, last_state_value, last_rate_of_change, delta_t_dynamic, beta_1, beta_2\n",
    "                )\n",
    "                last_update_times[col] = t\n",
    "\n",
    "        polling_index += 1\n",
    "\n",
    "    average_aoii_per_node = {col: cumulative_aoii_per_node[col] / num_time_steps for col in columns}\n",
    "    overall_average_aoii = sum(average_aoii_per_node.values()) / len(columns)\n",
    "\n",
    "    return average_aoii_per_node, overall_average_aoii\n",
    "\n",
    "average_aoii_per_node, overall_average_aoii = run_simulation_round_robin_aoii_tracking(pivot_df, columns)\n",
    "print(\"Overall Average AoII (Round Robin):\", overall_average_aoii)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Average AoII (AOI-based technique with M limit): 0.7219732013702596\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset and preprocess\n",
    "pivot_df = pd.read_csv(\"simulated_office_environment.csv\")\n",
    "pivot_df = pivot_df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "pivot_df = pivot_df.head(10000)\n",
    "\n",
    "initial_value = 20\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.01\n",
    "columns = [col for col in pivot_df.columns if col != \"SN\"]\n",
    "num_nodes = len(columns)\n",
    "num_time_steps = len(pivot_df)\n",
    "\n",
    "def calculate_aoii_sink(current_time, last_received_time, last_rate_of_change):\n",
    "    time_diff = current_time - last_received_time\n",
    "    if np.isnan(last_rate_of_change) or np.isinf(last_rate_of_change):\n",
    "        return 0.0\n",
    "    return abs(time_diff * last_rate_of_change)\n",
    "\n",
    "def update_node_state_dewma(measured_value, last_state_value, last_rate_of_change, delta_t, beta_1, beta_2):\n",
    "    if delta_t == 0:\n",
    "        return measured_value, last_rate_of_change\n",
    "    x1 = beta_1 * measured_value + (1 - beta_1) * (last_state_value + last_rate_of_change * delta_t)\n",
    "    x2 = beta_2 * (x1 - last_state_value) / delta_t + (1 - beta_2) * last_rate_of_change\n",
    "    return x1, x2\n",
    "\n",
    "def run_simulation_aoi_based_tracking_with_limit(pivot_df, columns, aoi_threshold, M):\n",
    "    last_update_times = {col: 0 for col in columns}\n",
    "    state_node = {col: np.array([20.0, 0.1]) for col in columns}\n",
    "    cumulative_aoii_per_node = {col: 0.0 for col in columns}\n",
    "    min_delta_t = 1\n",
    "\n",
    "    for t in range(len(pivot_df)):\n",
    "        aoi_values = {col: t - last_update_times[col] for col in columns}\n",
    "\n",
    "        for col in columns:\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "            current_aoii = calculate_aoii_sink(t, last_update_times[col], last_rate_of_change)\n",
    "            cumulative_aoii_per_node[col] += current_aoii\n",
    "\n",
    "        # Select top M nodes with the highest AOI exceeding the threshold\n",
    "        eligible_nodes = [col for col, aoi in aoi_values.items() if aoi >= aoi_threshold]\n",
    "        nodes_to_poll = sorted(eligible_nodes, key=lambda x: aoi_values[x], reverse=True)[:M]\n",
    "\n",
    "        for col in nodes_to_poll:\n",
    "            measured_value = pivot_df.loc[t, col]\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "            delta_t_dynamic = max(min_delta_t, t - last_update_times[col])\n",
    "            state_node[col] = update_node_state_dewma(\n",
    "                measured_value, last_state_value, last_rate_of_change, delta_t_dynamic, beta_1, beta_2\n",
    "            )\n",
    "            last_update_times[col] = t\n",
    "\n",
    "    average_aoii_per_node = {col: cumulative_aoii_per_node[col] / num_time_steps for col in columns}\n",
    "    overall_average_aoii = sum(average_aoii_per_node.values()) / len(columns)\n",
    "\n",
    "    return average_aoii_per_node, overall_average_aoii\n",
    "\n",
    "aoi_threshold = 0\n",
    "M = 1\n",
    "average_aoii_per_node, overall_average_aoii = run_simulation_aoi_based_tracking_with_limit(pivot_df, columns, aoi_threshold, M)\n",
    "print(\"Overall Average AoII (AOI-based technique with M limit):\", overall_average_aoii)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Kalman Filter simulation to calculate average AOI...\n",
      "Overall Average AOI: 0.03224797293651896\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset and preprocess\n",
    "pivot_df = pd.read_csv(\"simulated_office_environment.csv\")\n",
    "pivot_df = pivot_df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "pivot_df = pivot_df.head(10000)\n",
    "\n",
    "# Define parameters\n",
    "num_sensors = pivot_df.shape[1]\n",
    "time_steps = pivot_df.shape[0]\n",
    "M = 1  # Number of sensors to poll at each time step\n",
    "\n",
    "dt = 1  # Time step\n",
    "A = np.array([[1, dt], [0, 1]])  # State transition matrix\n",
    "H = np.array([[1, 0]])\n",
    "Q = np.array([[1e-3, 0], [0, 1e-3]])\n",
    "R = np.array([[0.5]])\n",
    "\n",
    "# Initialise Kalman Filter states\n",
    "X = np.zeros((num_sensors, 2, 1))\n",
    "X[:, 0, 0] = pivot_df.iloc[0, :].values\n",
    "X[:, 1, 0] = 0\n",
    "P = np.array([np.eye(2) for _ in range(num_sensors)])\n",
    "\n",
    "# Track last update times for AOI calculation\n",
    "last_update_times = np.zeros(num_sensors)\n",
    "cumulative_aoi = np.zeros(num_sensors)\n",
    "\n",
    "print(\"Running Kalman Filter simulation to calculate average AOI...\")\n",
    "for t in range(1, time_steps):\n",
    "    # Prediction step\n",
    "    for i in range(num_sensors):\n",
    "        X[i] = A @ X[i]\n",
    "        P[i] = A @ P[i] @ A.T + Q\n",
    "\n",
    "    # Select M sensors to poll based on largest AOI (calculated as rate of change × time since last update)\n",
    "    current_aoi = np.array([(t - last_update_times[i]) * abs(X[i, 1, 0]) for i in range(num_sensors)])\n",
    "    polled_indices = np.argsort(current_aoi)[-M:]\n",
    "\n",
    "    # Update step for polled sensors\n",
    "    for i in polled_indices:\n",
    "        Z = np.array([[pivot_df.iloc[t, i]]])\n",
    "        y = Z - (H @ X[i])\n",
    "        S = H @ P[i] @ H.T + R\n",
    "        K = P[i] @ H.T @ np.linalg.inv(S)\n",
    "        X[i] = X[i] + K @ y\n",
    "        P[i] = (np.eye(2) - K @ H) @ P[i]\n",
    "        last_update_times[i] = t\n",
    "\n",
    "    # Accumulate AOI for all sensors at each time step\n",
    "    cumulative_aoi += current_aoi\n",
    "\n",
    "# Calculate average AOI per sensor and overall average AOI\n",
    "average_aoi_per_sensor = cumulative_aoi / time_steps\n",
    "overall_average_aoi = np.mean(average_aoi_per_sensor)\n",
    "\n",
    "print(\"Overall Average AOI:\", overall_average_aoi)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
