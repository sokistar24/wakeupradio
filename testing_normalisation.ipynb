{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transmission Count by Category:\n",
      "Category A: 124 times\n",
      "Category B: 645 times\n",
      "\n",
      "Dynamic Penalty Statistics:\n",
      "Average Penalty: 19.4107\n",
      "Maximum Penalty: 26.0190\n",
      "Minimum Penalty: 0.0000\n",
      "\n",
      "Nodes Polled Statistics:\n",
      "Average Nodes Polled per Time Step: 0.08\n",
      "Maximum Nodes Polled at any Time Step: 10\n",
      "Target Maximum (M): 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset and preprocess\n",
    "#pivot_df = pd.read_csv(\"synthetic_scenario_30_nodes.csv\")\n",
    "#pivot_df = pd.read_csv(\"simulated_office_environment.csv\")\n",
    "pivot_df = pd.read_csv(\"synthetic_temp_polling_data.csv\")\n",
    "\n",
    "pivot_df = pivot_df.apply(lambda x: x.fillna(x.mean()), axis=0)  # Fill missing values\n",
    "pivot_df = pivot_df.head(10000)  # Restrict to first 20000 time steps\n",
    "\n",
    "# Parameters\n",
    "reward = 0.5\n",
    "M = 2 # Maximum number of nodes that can be polled\n",
    "theta = 0.5  # Threshold for reward condition\n",
    "penalty = -0.5  # Penalty for polling when difference is <= theta\n",
    "initial_value = 20  # Initial estimate for last polled values\n",
    "\n",
    "# Set parameters\n",
    "beta_1 = 0.9  # dEWMA parameter for state value\n",
    "beta_2 = 0.01 # dEWMA parameter for rate of change\n",
    "\n",
    "# Extract column names, ensuring \"SN\" is excluded\n",
    "columns = [col for col in pivot_df.columns if col != \"SN\"]\n",
    "num_nodes = len(columns)  # Number of sensor nodes based on dataset columns\n",
    "num_time_steps = len(pivot_df)  # Total time steps based on dataset length\n",
    "\n",
    "# Track the number of times each category is pulled\n",
    "category_counts = {'Category A': 0, 'Category B': 0}\n",
    "\n",
    "# Function to calculate Age of Incorrect Information (AoII) at the sink\n",
    "def calculate_aoii_sink(current_time, last_received_time, last_rate_of_change):\n",
    "    # Handle potential NaN or Inf values\n",
    "    time_diff = current_time - last_received_time\n",
    "    if np.isnan(last_rate_of_change) or np.isinf(last_rate_of_change):\n",
    "        return 0.0  # Default to zero if rate of change is invalid\n",
    "    return abs(time_diff * last_rate_of_change)\n",
    "\n",
    "# Helper function to update state using dEWMA\n",
    "def update_node_state_dewma(measured_value, last_state_value, last_rate_of_change, delta_t, beta_1, beta_2):\n",
    "    # Handle the case where delta_t is 0 to avoid division by zero\n",
    "    if delta_t == 0:\n",
    "        return measured_value, last_rate_of_change  # Return measured value and keep the last rate of change\n",
    "    \n",
    "    x1 = beta_1 * measured_value + (1 - beta_1) * (last_state_value + last_rate_of_change * delta_t)\n",
    "    x2 = beta_2 * (x1 - last_state_value) / delta_t + (1 - beta_2) * last_rate_of_change\n",
    "    return x1, x2\n",
    "\n",
    "# Helper function to calculate reward\n",
    "def calculate_reward(measured_value, last_state_value, theta, penalty):\n",
    "    if abs(measured_value - last_state_value) > theta:\n",
    "        return reward  # Reward\n",
    "    return penalty  # Penalty\n",
    "\n",
    "# Function to extract numeric node ID from column names dynamically, ensuring valid extraction\n",
    "def extract_node_id(col_name):\n",
    "    \"\"\"Extract numeric node ID from column name, handling cases where no digits are found.\"\"\"\n",
    "    digits = ''.join(filter(str.isdigit, col_name))\n",
    "    return int(digits) if digits else None  # Return None if no digits are found\n",
    "\n",
    "# Dynamic Penalty Update algorithm based on Whittle indices\n",
    "def dynamic_penalty_update(whittle_indices, M, current_lambda):\n",
    "    # Convert dictionary values to a list of whittle indices, handling any NaN values\n",
    "    c_values = []\n",
    "    for v in whittle_indices.values():\n",
    "        if np.isnan(v):\n",
    "            c_values.append(-float('inf'))  # Treat NaN as negative infinity (won't be polled)\n",
    "        else:\n",
    "            c_values.append(v)\n",
    "    \n",
    "    # Identify the set ℰ of nodes where c_i > λ(t)\n",
    "    eligible_nodes = [i for i, c_i in enumerate(c_values) if c_i > current_lambda]\n",
    "    \n",
    "    # If |ℰ| ≤ M, no penalty update needed\n",
    "    if len(eligible_nodes) <= M:\n",
    "        return current_lambda\n",
    "    \n",
    "    # Sort the c_i values in descending order\n",
    "    sorted_c_values = sorted(c_values, reverse=True)\n",
    "    \n",
    "    # Identify the M-th value\n",
    "    M_th_value = sorted_c_values[M-1]\n",
    "    \n",
    "    # Update penalty to the M-th value\n",
    "    new_lambda = M_th_value\n",
    "    \n",
    "    return new_lambda\n",
    "\n",
    "# Main function to simulate Whittle AoII with rewards and track transmission counts\n",
    "def run_simulation_whittle_aoii_dynamic_penalty(pivot_df, columns, M, theta, penalty):\n",
    "    cumulative_reward = 0  # Track total cumulative reward\n",
    "    cumulative_rewards = []  # Store cumulative average reward over time\n",
    "    last_update_times = {col: 0 for col in columns}  # Last update time for each node\n",
    "    state_node = {col: np.array([20.0, 0.1]) for col in columns}  # Node states\n",
    "    \n",
    "    # Initialize dynamic penalty (λ) to 0\n",
    "    aoii_penalty = 0.0\n",
    "    \n",
    "    # Track penalty evolution\n",
    "    penalty_values = [aoii_penalty]\n",
    "    \n",
    "    # Track nodes polled at each time step\n",
    "    nodes_polled_count = []\n",
    "    \n",
    "    # Set minimum timestamp difference to avoid division by zero\n",
    "    min_delta_t = 1  # Minimum time difference of 1 to avoid division by zero\n",
    "\n",
    "    for t in range(len(pivot_df)):\n",
    "        # Step 1: Compute Whittle indices for each node based on AoII\n",
    "        whittle_indices = {}\n",
    "        for col in columns:\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "            measured_value = pivot_df.loc[t, col]\n",
    "\n",
    "            # Correct AoII calculation at the sink using rate of change\n",
    "            current_aoii = calculate_aoii_sink(t, last_update_times[col], last_rate_of_change)\n",
    "            future_aoii_passive = calculate_aoii_sink(t+1, last_update_times[col], last_rate_of_change)\n",
    "            future_aoii_active = 0  # AoII resets to 0 if polled\n",
    "\n",
    "            # Whittle index calculations - with safety checks for NaN/Inf values\n",
    "            q_passive = current_aoii + future_aoii_passive\n",
    "            q_active = current_aoii + future_aoii_active + aoii_penalty\n",
    "            \n",
    "            # Calculate the Whittle index with safeguards against invalid values\n",
    "            whittle_index = q_passive - q_active\n",
    "            \n",
    "            # Handle NaN or Inf values\n",
    "            if np.isnan(whittle_index) or np.isinf(whittle_index):\n",
    "                whittle_indices[col] = -float('inf')  # Set to negative infinity if invalid\n",
    "            else:\n",
    "                whittle_indices[col] = whittle_index\n",
    "\n",
    "        # Step 2: Update the dynamic penalty (λ) using the algorithm\n",
    "        aoii_penalty = dynamic_penalty_update(whittle_indices, M, aoii_penalty)\n",
    "        penalty_values.append(aoii_penalty)\n",
    "        \n",
    "        # Step 3: Select nodes to poll based on the updated penalty\n",
    "        nodes_to_poll = [col for col in whittle_indices if whittle_indices[col] >= aoii_penalty]\n",
    "        nodes_polled_count.append(len(nodes_to_poll))\n",
    "\n",
    "        # Step 4: Poll selected nodes and calculate rewards\n",
    "        for col in nodes_to_poll:\n",
    "            measured_value = pivot_df.loc[t, col]\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "\n",
    "            # Calculate reward after polling\n",
    "            reward = calculate_reward(measured_value, last_state_value, theta, penalty)\n",
    "            cumulative_reward += reward  # Update cumulative reward\n",
    "\n",
    "            delta_t_dynamic = max(min_delta_t, t - last_update_times[col])  # Time since last update (ensure at least 1)\n",
    "\n",
    "            # Update node state and last update time\n",
    "            state_node[col] = update_node_state_dewma(\n",
    "                measured_value, last_state_value, last_rate_of_change, delta_t_dynamic, beta_1=beta_1, beta_2=beta_2\n",
    "            )\n",
    "            last_update_times[col] = t\n",
    "\n",
    "            # Extract node ID dynamically and categorize\n",
    "            node_id = extract_node_id(col)\n",
    "            if node_id is not None:\n",
    "                if 1 <= node_id <= 5:\n",
    "                    category_counts['Category A'] += 1\n",
    "                elif 6 <= node_id <= 10:\n",
    "                    category_counts['Category B'] += 1\n",
    "             \n",
    "\n",
    "        # Step 5: Calculate cumulative average reward\n",
    "        cumulative_rewards.append(cumulative_reward / (t + 1))\n",
    "\n",
    "    return cumulative_rewards, category_counts, penalty_values, nodes_polled_count\n",
    "\n",
    "# Run the simulation with dynamic penalty\n",
    "cumulative_rewards_whittle, category_pulled_counts, penalty_values, nodes_polled_count = run_simulation_whittle_aoii_dynamic_penalty(\n",
    "    pivot_df, columns, M, theta, penalty\n",
    ")\n",
    "\n",
    "# Print the number of times each category was pulled\n",
    "print(\"Transmission Count by Category:\")\n",
    "for category, count in category_pulled_counts.items():\n",
    "    print(f\"{category}: {count} times\")\n",
    "\n",
    "# Save cumulative rewards to CSV\n",
    "pd.DataFrame(cumulative_rewards_whittle, columns=[\"cumulative_reward\"]).to_csv(\n",
    "    \"cumulative_rewards_whittle_dynamic_penalty.csv\", index=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Calculate statistics about the penalty values and nodes polled\n",
    "avg_penalty = np.mean(penalty_values)\n",
    "max_penalty = np.max(penalty_values)\n",
    "min_penalty = np.min(penalty_values)\n",
    "avg_nodes_polled = np.mean(nodes_polled_count)\n",
    "max_nodes_polled = np.max(nodes_polled_count)\n",
    "\n",
    "print(f\"\\nDynamic Penalty Statistics:\")\n",
    "print(f\"Average Penalty: {avg_penalty:.4f}\")\n",
    "print(f\"Maximum Penalty: {max_penalty:.4f}\")\n",
    "print(f\"Minimum Penalty: {min_penalty:.4f}\")\n",
    "print(f\"\\nNodes Polled Statistics:\")\n",
    "print(f\"Average Nodes Polled per Time Step: {avg_nodes_polled:.2f}\")\n",
    "print(f\"Maximum Nodes Polled at any Time Step: {max_nodes_polled}\")\n",
    "print(f\"Target Maximum (M): {M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transmission Count by Category:\n",
      "Category A: 81 times\n",
      "Category B: 403 times\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#pivot_df = pd.read_csv(\"synthetic_scenario_30_nodes.csv\")\n",
    "pivot_df = pd.read_csv(\"synthetic_temp_polling_data.csv\")\n",
    "pivot_df = pivot_df.head(20000)  # Restrict to first 20000 time steps\n",
    "\n",
    "\n",
    "M = 2  # Maximum number of nodes that can be polled\n",
    "aoii_penalty = 0.5\n",
    "initial_value = 20  # Initial estimate for last polled values\n",
    "\n",
    "# Set parameters\n",
    "beta_1 = 0.95  # dEWMA parameter for state value\n",
    "beta_2 = 0.1 # dEWMA parameter for rate of change\n",
    "\n",
    "# Extract column names, ensuring \"SN\" is excluded\n",
    "columns = [col for col in pivot_df.columns if col != \"SN\"]\n",
    "num_nodes = len(columns)  # Number of sensor nodes based on dataset columns\n",
    "num_time_steps = len(pivot_df)  # Total time steps based on dataset length\n",
    "\n",
    "# Track the number of times each category is pulled\n",
    "category_counts = {'Category A': 0, 'Category B': 0}\n",
    "\n",
    "# Function to calculate Age of Incorrect Information (AoII) at the sink\n",
    "def calculate_aoii_sink(current_time, last_received_time, last_rate_of_change):\n",
    "    return abs((current_time - last_received_time) * last_rate_of_change)\n",
    "\n",
    "# Helper function to update state using dEWMA\n",
    "def update_node_state_dewma(measured_value, last_state_value, last_rate_of_change, delta_t, beta_1, beta_2):\n",
    "    x1 = beta_1 * measured_value + (1 - beta_1) * (last_state_value + last_rate_of_change * delta_t)\n",
    "    x2 = beta_2 * (x1 - last_state_value) / delta_t + (1 - beta_2) * last_rate_of_change\n",
    "    return x1, x2\n",
    "\n",
    "\n",
    "# Function to extract numeric node ID from column names dynamically, ensuring valid extraction\n",
    "def extract_node_id(col_name):\n",
    "    \"\"\"Extract numeric node ID from column name, handling cases where no digits are found.\"\"\"\n",
    "    digits = ''.join(filter(str.isdigit, col_name))\n",
    "    return int(digits) if digits else None  # Return None if no digits are found\n",
    "\n",
    "# Main function to simulate Whittle AoII with rewards and track transmission counts\n",
    "def run_simulation_whittle_aoii(pivot_df, columns, M, aoii_penalty):\n",
    "    \n",
    "    last_update_times = {col: 0 for col in columns}  # Last update time for each node\n",
    "    state_node = {col: np.array([20.0, 0.1]) for col in columns}  # Node states\n",
    "\n",
    "    for t in range(len(pivot_df)):\n",
    "        # Step 1: Compute Whittle indices for each node based on AoII\n",
    "        whittle_indices = {}\n",
    "        for col in columns:\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "            measured_value = pivot_df.loc[t, col]\n",
    "\n",
    "            # Correct AoII calculation at the sink using rate of change\n",
    "            current_aoii = calculate_aoii_sink(t, last_update_times[col], last_rate_of_change)\n",
    "            future_aoii_passive = calculate_aoii_sink(t+1, last_update_times[col], last_rate_of_change)\n",
    "            future_aoii_active = 0  # AoII resets to 0 if polled\n",
    "\n",
    "            # Whittle index calculations\n",
    "            q_passive = current_aoii + future_aoii_passive\n",
    "            q_active = current_aoii + future_aoii_active + aoii_penalty\n",
    "            whittle_indices[col] = q_passive - q_active\n",
    "\n",
    "        # Step 2: Select top M nodes to poll based on Whittle indices\n",
    "        nodes_to_poll = [col for col in whittle_indices if whittle_indices[col] >= 0]\n",
    "        if len(nodes_to_poll) > M:\n",
    "            nodes_to_poll = sorted(nodes_to_poll, key=whittle_indices.get, reverse=True)[:M]\n",
    "\n",
    "        # Step 3: Poll selected nodes and calculate rewards\n",
    "        for col in nodes_to_poll:\n",
    "            measured_value = pivot_df.loc[t, col]\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "\n",
    "            delta_t_dynamic = t - last_update_times[col]  # Time since last update\n",
    "\n",
    "            # Update node state and last update time\n",
    "            state_node[col] = update_node_state_dewma(\n",
    "                measured_value, last_state_value, last_rate_of_change, delta_t_dynamic, beta_1=beta_1, beta_2=beta_2\n",
    "            )\n",
    "            last_update_times[col] = t\n",
    "\n",
    "            # Extract node ID dynamically and categorize\n",
    "            node_id = extract_node_id(col)\n",
    "            if node_id is not None:\n",
    "                if 1 <= node_id <= 5:\n",
    "                    category_counts['Category A'] += 1\n",
    "                elif 6 <= node_id <= 10:\n",
    "                    category_counts['Category B'] += 1\n",
    "\n",
    "\n",
    "    return  category_counts\n",
    "\n",
    "# Run the simulation\n",
    "category_pulled_counts = run_simulation_whittle_aoii(\n",
    "    pivot_df, columns, M, aoii_penalty\n",
    ")\n",
    "\n",
    "# Print the number of times each category was pulled\n",
    "print(\"Transmission Count by Category:\")\n",
    "for category, count in category_pulled_counts.items():\n",
    "    print(f\"{category}: {count} times\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transmission Count by Category:\n",
      "Category A: 14134 times\n",
      "Category B: 11964 times\n",
      "Category C: 0 times\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and restrict data\n",
    "pivot_df = pd.read_csv(\"synthetic_temp_polling_data.csv\").head(20000)\n",
    "#pivot_df = pd.read_csv(\"synthetic_scenario_30_nodes_2.csv\").head(20000)\n",
    "\n",
    "# Parameters\n",
    "M = 2  # Max nodes to poll simultaneously\n",
    "aoii_penalty = 0.5\n",
    "beta_1 = 0.1\n",
    "beta_2 = 0.1\n",
    "\n",
    "columns = [col for col in pivot_df.columns if col != \"SN\"]\n",
    "\n",
    "# Initialize tracking variables\n",
    "last_update_times = {col: 0 for col in columns}\n",
    "state_node = {col: np.array([50.0, 0.1]) for col in columns}\n",
    "temp_min_max_history = {col: {'min': float('inf'), 'max': float('-inf')} for col in columns}\n",
    "category_counts = {'Category A': 0, 'Category B': 0, 'Category C': 0}\n",
    "\n",
    "# Functions\n",
    "def calculate_aoii_sink(current_time, last_received_time, normalised_rate_of_change):\n",
    "    return abs((current_time - last_received_time) * normalised_rate_of_change)\n",
    "\n",
    "def update_node_state_dewma(measured_value, last_state_value, last_rate_of_change, delta_t, beta_1, beta_2):\n",
    "    x1 = beta_1 * measured_value + (1 - beta_1) * (last_state_value + last_rate_of_change * delta_t)\n",
    "    x2 = beta_2 * (x1 - last_state_value) / delta_t + (1 - beta_2) * last_rate_of_change\n",
    "    return x1, x2\n",
    "\n",
    "def extract_node_id(col_name):\n",
    "    digits = ''.join(filter(str.isdigit, col_name))\n",
    "    return int(digits) if digits else None\n",
    "\n",
    "# Main simulation loop\n",
    "for t in range(len(pivot_df)):\n",
    "    whittle_indices = {}\n",
    "\n",
    "    for col in columns:\n",
    "        measured_value = pivot_df.loc[t, col]\n",
    "\n",
    "        # Update min/max dynamically for normalisation\n",
    "        temp_min_max_history[col]['min'] = min(temp_min_max_history[col]['min'], measured_value)\n",
    "        temp_min_max_history[col]['max'] = max(temp_min_max_history[col]['max'], measured_value)\n",
    "        min_temp = temp_min_max_history[col]['min']\n",
    "        max_temp = temp_min_max_history[col]['max']\n",
    "\n",
    "        epsilon = 1e-6  # avoid division by zero\n",
    "        normalised_temp = (measured_value - min_temp) / (max_temp - min_temp + epsilon)\n",
    "\n",
    "        # Calculate normalised rate of change\n",
    "        if t > 0:\n",
    "            prev_value = pivot_df.loc[t-1, col]\n",
    "            prev_norm_temp = (prev_value - min_temp) / (max_temp - min_temp + epsilon)\n",
    "            normalised_rate_of_change = abs(normalised_temp - prev_norm_temp)\n",
    "        else:\n",
    "            normalised_rate_of_change = 0\n",
    "\n",
    "        current_aoii = calculate_aoii_sink(t, last_update_times[col], normalised_rate_of_change)\n",
    "        future_aoii_passive = calculate_aoii_sink(t+1, last_update_times[col], normalised_rate_of_change)\n",
    "        future_aoii_active = 0\n",
    "\n",
    "        q_passive = current_aoii + future_aoii_passive\n",
    "        q_active = current_aoii + future_aoii_active + aoii_penalty\n",
    "        whittle_indices[col] = q_passive - q_active\n",
    "\n",
    "    # Poll decision\n",
    "    nodes_to_poll = [col for col in whittle_indices if whittle_indices[col] >= 0]\n",
    "    if len(nodes_to_poll) > M:\n",
    "        nodes_to_poll = sorted(nodes_to_poll, key=whittle_indices.get, reverse=True)[:M]\n",
    "\n",
    "    for col in nodes_to_poll:\n",
    "        measured_value = pivot_df.loc[t, col]\n",
    "        last_state_value, last_rate_of_change = state_node[col]\n",
    "\n",
    "        delta_t_dynamic = t - last_update_times[col]\n",
    "\n",
    "        state_node[col] = update_node_state_dewma(\n",
    "            measured_value, last_state_value, last_rate_of_change, delta_t_dynamic, beta_1, beta_2\n",
    "        )\n",
    "        last_update_times[col] = t\n",
    "\n",
    "        # Track polling count by category\n",
    "        node_id = extract_node_id(col)\n",
    "        if node_id:\n",
    "            if 1 <= node_id <= 5:\n",
    "                category_counts['Category A'] += 1\n",
    "            elif 6 <= node_id <= 10:\n",
    "                category_counts['Category B'] += 1\n",
    "            elif 21 <= node_id <= 30:\n",
    "                category_counts['Category C'] += 1\n",
    "\n",
    "# Display polling counts\n",
    "print(\"Transmission Count by Category:\")\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"{category}: {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transmission Count by Category:\n",
      "Category A: 64 times\n",
      "Category B: 30 times\n",
      "Category C: 0 times\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and restrict data\n",
    "pivot_df = pd.read_csv(\"synthetic_temp_polling_data.csv\").head(20000)\n",
    "\n",
    "# Parameters\n",
    "M = 4  # Maximum nodes polled simultaneously\n",
    "aoii_penalty = 0.3\n",
    "beta_1 = 0.98\n",
    "beta_2 = 0.98\n",
    "\n",
    "columns = [col for col in pivot_df.columns if col != \"SN\"]\n",
    "\n",
    "# Initialize tracking variables\n",
    "last_update_times = {col: 0 for col in columns}\n",
    "state_node = {col: np.array([20, 0.1]) for col in columns}  # Initialized as normalised\n",
    "value_min_max_history = {col: {'min': float('inf'), 'max': float('-inf')} for col in columns}\n",
    "category_counts = {'Category A': 0, 'Category B': 0, 'Category C': 0}\n",
    "\n",
    "# Functions\n",
    "def calculate_aoii_sink(current_time, last_received_time, normalised_rate_of_change):\n",
    "    return abs((current_time - last_received_time) * normalised_rate_of_change)\n",
    "\n",
    "def update_node_state_dewma(norm_measured_value, last_state_value, last_rate_of_change, delta_t, beta_1, beta_2):\n",
    "    x1 = beta_1 * norm_measured_value + (1 - beta_1) * (last_state_value + last_rate_of_change * delta_t)\n",
    "    x2 = beta_2 * (x1 - last_state_value) / delta_t + (1 - beta_2) * last_rate_of_change\n",
    "    return x1, x2\n",
    "\n",
    "def extract_node_id(col_name):\n",
    "    digits = ''.join(filter(str.isdigit, col_name))\n",
    "    return int(digits) if digits else None\n",
    "\n",
    "# Main simulation loop\n",
    "for t in range(len(pivot_df)):\n",
    "    whittle_indices = {}\n",
    "\n",
    "    for col in columns:\n",
    "        last_state_value, last_rate_of_change = state_node[col]\n",
    "        delta_t_dynamic = t - last_update_times[col]\n",
    "\n",
    "        # Estimate the normalised state at sink (without new measurement)\n",
    "        estimated_norm_value = last_state_value + last_rate_of_change * delta_t_dynamic\n",
    "        normalised_rate_of_change = abs(last_rate_of_change)\n",
    "\n",
    "        current_aoii = calculate_aoii_sink(t, last_update_times[col], normalised_rate_of_change)\n",
    "        future_aoii_passive = calculate_aoii_sink(t + 1, last_update_times[col], normalised_rate_of_change)\n",
    "        future_aoii_active = 0\n",
    "\n",
    "        q_passive = current_aoii + future_aoii_passive\n",
    "        q_active = current_aoii + future_aoii_active + aoii_penalty\n",
    "        whittle_indices[col] = q_passive - q_active\n",
    "\n",
    "    # Poll decision\n",
    "    nodes_to_poll = [col for col in whittle_indices if whittle_indices[col] >= 0]\n",
    "    if len(nodes_to_poll) > M:\n",
    "        nodes_to_poll = sorted(nodes_to_poll, key=whittle_indices.get, reverse=True)[:M]\n",
    "\n",
    "    for col in nodes_to_poll:\n",
    "        measured_value = pivot_df.loc[t, col]\n",
    "\n",
    "        # Dynamically update min/max and normalise measured value\n",
    "        value_min_max_history[col]['min'] = min(value_min_max_history[col]['min'], measured_value)\n",
    "        value_min_max_history[col]['max'] = max(value_min_max_history[col]['max'], measured_value)\n",
    "        min_val = value_min_max_history[col]['min']\n",
    "        max_val = value_min_max_history[col]['max']\n",
    "\n",
    "        epsilon = 1e-6\n",
    "        normalised_measurement = (measured_value - min_val) / (max_val - min_val + epsilon)\n",
    "\n",
    "        last_state_value, last_rate_of_change = state_node[col]\n",
    "        delta_t_dynamic = t - last_update_times[col]\n",
    "\n",
    "        # Update state using normalised measurement\n",
    "        state_node[col] = update_node_state_dewma(\n",
    "            normalised_measurement, last_state_value, last_rate_of_change, delta_t_dynamic, beta_1, beta_2\n",
    "        )\n",
    "        last_update_times[col] = t\n",
    "\n",
    "        # Track polling count by category\n",
    "        node_id = extract_node_id(col)\n",
    "        if node_id:\n",
    "            if 1 <= node_id <= 5:\n",
    "                category_counts['Category A'] += 1\n",
    "            elif 6 <= node_id <= 10:\n",
    "                category_counts['Category B'] += 1\n",
    "            elif 21 <= node_id <= 30:\n",
    "                category_counts['Category C'] += 1\n",
    "\n",
    "# Display polling counts\n",
    "print(\"Transmission Count by Category:\")\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"{category}: {count} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transmission Count by Category:\n",
      "Category A: 67 times\n",
      "Category B: 43 times\n",
      "Category C: 0 times\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and restrict data\n",
    "pivot_df = pd.read_csv(\"synthetic_temp_polling_data.csv\").head(20000)\n",
    "\n",
    "# Parameters\n",
    "M = 2  # Maximum nodes polled simultaneously\n",
    "aoii_penalty = 0.5\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.9\n",
    "\n",
    "columns = [col for col in pivot_df.columns if col != \"SN\"]\n",
    "\n",
    "# Initialize tracking variables\n",
    "last_update_times = {col: 0 for col in columns}\n",
    "state_node = {col: np.array([50, 0.1]) for col in columns}  # Initialised in normalised scale\n",
    "value_min_max_history = {col: {'min': float('inf'), 'max': float('-inf')} for col in columns}\n",
    "category_counts = {'Category A': 0, 'Category B': 0, 'Category C': 0}\n",
    "\n",
    "# Functions\n",
    "def calculate_aoii_sink(current_time, last_received_time, normalised_rate_of_change):\n",
    "    return abs((current_time - last_received_time) * normalised_rate_of_change)\n",
    "\n",
    "def update_node_state_dewma(normalised_measured_value, normalised_last_state_value, last_rate_of_change, delta_t, beta_1, beta_2):\n",
    "    x1 = beta_1 * normalised_measurement + (1 - beta_1) * (last_state_value + last_rate_of_change * delta_t)\n",
    "    x2 = beta_2 * (x1 - last_state_value) / delta_t + (1 - beta_2) * last_rate_of_change\n",
    "    return x1, x2\n",
    "\n",
    "def extract_node_id(col_name):\n",
    "    digits = ''.join(filter(str.isdigit, col_name))\n",
    "    return int(digits) if digits else None\n",
    "\n",
    "# Main simulation loop\n",
    "for t in range(len(pivot_df)):\n",
    "    whittle_indices = {}\n",
    "\n",
    "    for col in columns:\n",
    "        last_state_value, last_rate_of_change = state_node[col]\n",
    "        delta_t_dynamic = t - last_update_times[col]\n",
    "\n",
    "        # Estimate normalised value at sink without new measurement\n",
    "        estimated_norm_value = last_state_value + last_rate_of_change * delta_t_dynamic\n",
    "        normalised_rate_of_change = abs(last_rate_of_change)\n",
    "\n",
    "        current_aoii = calculate_aoii_sink(t, last_update_times[col], normalised_rate_of_change)\n",
    "        future_aoii_passive = calculate_aoii_sink(t + 1, last_update_times[col], normalised_rate_of_change)\n",
    "        future_aoii_active = 0\n",
    "\n",
    "        q_passive = current_aoii + future_aoii_passive\n",
    "        q_active = current_aoii + future_aoii_active + aoii_penalty\n",
    "        whittle_indices[col] = q_passive - q_active\n",
    "\n",
    "    # Poll decision\n",
    "    nodes_to_poll = [col for col in whittle_indices if whittle_indices[col] >= 0]\n",
    "    if len(nodes_to_poll) > M:\n",
    "        nodes_to_poll = sorted(nodes_to_poll, key=whittle_indices.get, reverse=True)[:M]\n",
    "\n",
    "    for col in nodes_to_poll:\n",
    "        measured_value = pivot_df.loc[t, col]\n",
    "\n",
    "        # Update min/max and normalise measured value upon receiving\n",
    "        value_min_max_history[col]['min'] = min(value_min_max_history[col]['min'], measured_value)\n",
    "        value_min_max_history[col]['max'] = max(value_min_max_history[col]['max'], measured_value)\n",
    "        min_val = value_min_max_history[col]['min']\n",
    "        max_val = value_min_max_history[col]['max']\n",
    "\n",
    "        epsilon = 1e-6\n",
    "        normalised_measurement = (measured_value - min_val) / (max_val - min_val + epsilon)\n",
    "\n",
    "        last_state_value, last_rate_of_change = state_node[col]\n",
    "        delta_t_dynamic = t - last_update_times[col]\n",
    "\n",
    "        # Update state using normalised values\n",
    "        state_node[col] = update_node_state_dewma(\n",
    "            normalised_measurement, last_state_value, last_rate_of_change, delta_t_dynamic, beta_1, beta_2\n",
    "        )\n",
    "        last_update_times[col] = t\n",
    "\n",
    "        # Track polling count by category\n",
    "        node_id = extract_node_id(col)\n",
    "        if node_id:\n",
    "            if 1 <= node_id <= 5:\n",
    "                category_counts['Category A'] += 1\n",
    "            elif 6 <= node_id <= 10:\n",
    "                category_counts['Category B'] += 1\n",
    "            elif 21 <= node_id <= 30:\n",
    "                category_counts['Category C'] += 1\n",
    "\n",
    "# Display polling counts\n",
    "print(\"Transmission Count by Category:\")\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"{category}: {count} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Adaptive Thresholds:\n",
      "node1: 1.0000\n",
      "node2: 1.0000\n",
      "node3: 1.0000\n",
      "node4: 1.0000\n",
      "node5: 1.0000\n",
      "node6: 1.0000\n",
      "node7: 1.0000\n",
      "node8: 1.0000\n",
      "node9: 1.0000\n",
      "node10: 1.0000\n",
      "\n",
      "Category Counts Comparison:\n",
      "Adaptive Thresholds: {'Category A': 521, 'Category B': 515}\n"
     ]
    }
   ],
   "source": [
    "# Add this adaptive threshold approach to your existing implementation\n",
    "\n",
    "# Function to calculate adaptive thresholds based on node variance\n",
    "def calculate_adaptive_threshold(values, base_theta, min_factor=0.5, max_factor=2.0):\n",
    "    \"\"\"\n",
    "    Calculate an adaptive threshold based on the variability of the sensor.\n",
    "    \n",
    "    Parameters:\n",
    "    - values: List of historical values for the sensor\n",
    "    - base_theta: Base threshold value (θ)\n",
    "    - min_factor: Minimum scaling factor\n",
    "    - max_factor: Maximum scaling factor\n",
    "    \n",
    "    Returns:\n",
    "    - Adaptive threshold value\n",
    "    \"\"\"\n",
    "    if len(values) < 2:\n",
    "        return base_theta\n",
    "    \n",
    "    # Calculate coefficient of variation (CV)\n",
    "    # CV = std / mean, which gives a normalized measure of dispersion\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if abs(mean) < 1e-10:\n",
    "        cv = 1.0  # Default to 1.0 if mean is near zero\n",
    "    else:\n",
    "        cv = std / abs(mean)\n",
    "    \n",
    "    # Scale threshold inversely with CV\n",
    "    # Higher variability (higher CV) -> lower threshold (more sensitive)\n",
    "    # Lower variability (lower CV) -> higher threshold (less sensitive)\n",
    "    scale_factor = 1.0 / max(cv, 0.1)  # Limit the maximum scale factor\n",
    "    \n",
    "    # Clamp the scale factor within reasonable bounds\n",
    "    scale_factor = max(min_factor, min(max_factor, scale_factor))\n",
    "    \n",
    "    return base_theta * scale_factor\n",
    "\n",
    "# Modified reward calculation function with adaptive thresholds\n",
    "def calculate_reward_adaptive(measured_value, last_state_value, node_adaptive_thresholds, col, base_penalty):\n",
    "    \"\"\"\n",
    "    Calculate reward using adaptive thresholds.\n",
    "    \n",
    "    Parameters:\n",
    "    - measured_value: Current measured value\n",
    "    - last_state_value: Previous state value\n",
    "    - node_adaptive_thresholds: Dictionary of adaptive thresholds for each node\n",
    "    - col: Column name (node identifier)\n",
    "    - base_penalty: Base penalty value\n",
    "    \n",
    "    Returns:\n",
    "    - Reward or penalty value\n",
    "    \"\"\"\n",
    "    # Get the adaptive threshold for this node\n",
    "    adaptive_theta = node_adaptive_thresholds[col]\n",
    "    \n",
    "    # Calculate reward based on adaptive threshold\n",
    "    if abs(measured_value - last_state_value) > adaptive_theta:\n",
    "        return reward  # Reward is kept constant\n",
    "    return base_penalty  # Use the base penalty\n",
    "\n",
    "# Function to initialize and manage adaptive thresholds\n",
    "def initialize_adaptive_thresholds(pivot_df, columns, base_theta, window_size=100):\n",
    "    \"\"\"\n",
    "    Initialize adaptive thresholds for each node.\n",
    "    \n",
    "    Parameters:\n",
    "    - pivot_df: DataFrame containing sensor data\n",
    "    - columns: List of column names representing sensor nodes\n",
    "    - base_theta: Base threshold value (θ)\n",
    "    - window_size: Size of the window for calculating statistics\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary of adaptive thresholds and window values for each node\n",
    "    \"\"\"\n",
    "    adaptive_info = {}\n",
    "    for col in columns:\n",
    "        # Use first window_size readings (or all if less) to initialize\n",
    "        initial_window_size = min(window_size, len(pivot_df))\n",
    "        values = pivot_df.loc[0:initial_window_size-1, col].values.tolist()\n",
    "        \n",
    "        # Calculate initial adaptive threshold\n",
    "        adaptive_theta = calculate_adaptive_threshold(values, base_theta)\n",
    "        \n",
    "        adaptive_info[col] = {\n",
    "            'threshold': adaptive_theta,\n",
    "            'window': values,\n",
    "            'window_size': window_size\n",
    "        }\n",
    "    \n",
    "    return adaptive_info\n",
    "\n",
    "# Function to update adaptive thresholds with new measurements\n",
    "def update_adaptive_thresholds(adaptive_info, col, new_value, base_theta):\n",
    "    \"\"\"\n",
    "    Update adaptive thresholds with new measurements.\n",
    "    \n",
    "    Parameters:\n",
    "    - adaptive_info: Dictionary containing threshold information\n",
    "    - col: Column name (node identifier)\n",
    "    - new_value: New measured value\n",
    "    - base_theta: Base threshold value (θ)\n",
    "    \n",
    "    Returns:\n",
    "    - Updated adaptive_info dictionary\n",
    "    \"\"\"\n",
    "    window = adaptive_info[col]['window']\n",
    "    window_size = adaptive_info[col]['window_size']\n",
    "    \n",
    "    # Add new value and remove oldest if window is full\n",
    "    window.append(new_value)\n",
    "    if len(window) > window_size:\n",
    "        window.pop(0)\n",
    "    \n",
    "    # Recalculate adaptive threshold\n",
    "    adaptive_info[col]['threshold'] = calculate_adaptive_threshold(window, base_theta)\n",
    "    \n",
    "    return adaptive_info\n",
    "\n",
    "# Modified main simulation function with adaptive thresholds\n",
    "def run_simulation_whittle_aoii_adaptive(pivot_df, columns, M, base_theta, base_penalty, adaptive_window_size=100):\n",
    "    cumulative_reward = 0\n",
    "    cumulative_rewards = []\n",
    "    last_update_times = {col: 0 for col in columns}\n",
    "    state_node = {col: np.array([pivot_df.loc[0, col], 0.1]) for col in columns}\n",
    "    \n",
    "    # Initialize adaptive thresholds\n",
    "    adaptive_info = initialize_adaptive_thresholds(pivot_df, columns, base_theta, adaptive_window_size)\n",
    "    \n",
    "    # Extract just the thresholds for easier access\n",
    "    node_adaptive_thresholds = {col: adaptive_info[col]['threshold'] for col in columns}\n",
    "    \n",
    "    # Initialize category counts\n",
    "    category_counts = {'Category A': 0, 'Category B': 0}\n",
    "    \n",
    "    # Initialize dynamic penalty\n",
    "    aoii_penalty = 0.0\n",
    "    penalty_values = [aoii_penalty]\n",
    "    nodes_polled_count = []\n",
    "    min_delta_t = 1\n",
    "\n",
    "    for t in range(len(pivot_df)):\n",
    "        # Calculate Whittle indices (standard calculation)\n",
    "        whittle_indices = {}\n",
    "        for col in columns:\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "            measured_value = pivot_df.loc[t, col]\n",
    "\n",
    "            current_aoii = calculate_aoii_sink(t, last_update_times[col], last_rate_of_change)\n",
    "            future_aoii_passive = calculate_aoii_sink(t+1, last_update_times[col], last_rate_of_change)\n",
    "            future_aoii_active = 0\n",
    "\n",
    "            q_passive = current_aoii + future_aoii_passive\n",
    "            q_active = current_aoii + future_aoii_active + aoii_penalty\n",
    "            \n",
    "            whittle_index = q_passive - q_active\n",
    "            \n",
    "            if np.isnan(whittle_index) or np.isinf(whittle_index):\n",
    "                whittle_indices[col] = -float('inf')\n",
    "            else:\n",
    "                whittle_indices[col] = whittle_index\n",
    "\n",
    "        # Update dynamic penalty\n",
    "        aoii_penalty = dynamic_penalty_update(whittle_indices, M, aoii_penalty)\n",
    "        penalty_values.append(aoii_penalty)\n",
    "        \n",
    "        # Select nodes to poll\n",
    "        nodes_to_poll = [col for col in whittle_indices if whittle_indices[col] >= aoii_penalty]\n",
    "        nodes_polled_count.append(len(nodes_to_poll))\n",
    "\n",
    "        # Poll selected nodes with adaptive thresholds for rewards\n",
    "        for col in nodes_to_poll:\n",
    "            measured_value = pivot_df.loc[t, col]\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "\n",
    "            # Calculate reward using adaptive threshold\n",
    "            reward_value = calculate_reward_adaptive(\n",
    "                measured_value, last_state_value, node_adaptive_thresholds, col, base_penalty\n",
    "            )\n",
    "            cumulative_reward += reward_value\n",
    "\n",
    "            delta_t_dynamic = max(min_delta_t, t - last_update_times[col])\n",
    "\n",
    "            # Update node state (standard update)\n",
    "            state_node[col] = update_node_state_dewma(\n",
    "                measured_value, last_state_value, last_rate_of_change, delta_t_dynamic, beta_1, beta_2\n",
    "            )\n",
    "            last_update_times[col] = t\n",
    "            \n",
    "            # Update adaptive thresholds with new measurement\n",
    "            adaptive_info = update_adaptive_thresholds(adaptive_info, col, measured_value, base_theta)\n",
    "            node_adaptive_thresholds[col] = adaptive_info[col]['threshold']\n",
    "\n",
    "            # Categorize based on node ID\n",
    "            node_id = extract_node_id(col)\n",
    "            if node_id is not None:\n",
    "                if 1 <= node_id <= 5:\n",
    "                    category_counts['Category A'] += 1\n",
    "                elif 6 <= node_id <= 10:\n",
    "                    category_counts['Category B'] += 1\n",
    "\n",
    "        # Calculate cumulative reward\n",
    "        cumulative_rewards.append(cumulative_reward / (t + 1))\n",
    "\n",
    "    return cumulative_rewards, category_counts, penalty_values, nodes_polled_count, node_adaptive_thresholds\n",
    "\n",
    "# Run the simulation with adaptive thresholds\n",
    "cumulative_rewards_adaptive, category_pulled_counts, penalty_values, nodes_polled_count, final_thresholds = run_simulation_whittle_aoii_adaptive(\n",
    "    pivot_df, columns, M, theta, penalty\n",
    ")\n",
    "\n",
    "# Print the adaptive thresholds at the end of simulation\n",
    "print(\"Final Adaptive Thresholds:\")\n",
    "for col, threshold in final_thresholds.items():\n",
    "    print(f\"{col}: {threshold:.4f}\")\n",
    "\n",
    "# Compare category counts between different approaches\n",
    "print(\"\\nCategory Counts Comparison:\")\n",
    "print(f\"Adaptive Thresholds: {category_pulled_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running normalized simulation...\n",
      "Step 0/20000...\n",
      "Step 5000/20000...\n",
      "Step 10000/20000...\n",
      "Step 15000/20000...\n",
      "\n",
      "RESULTS:\n",
      "Category A: 72 polls\n",
      "Category B: 14 polls\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "pivot_df = pd.read_csv(\"synthetic_temp_polling_data.csv\")\n",
    "pivot_df = pivot_df.head(20000)  # Restrict to first 20000 time steps\n",
    "\n",
    "M = 2  # Maximum number of nodes that can be polled\n",
    "aoii_penalty = 0.5\n",
    "initial_value = 20  # Initial estimate for last polled values\n",
    "\n",
    "# Set parameters\n",
    "beta_1 = 0.95  # dEWMA parameter for state value\n",
    "beta_2 = 0.99   # dEWMA parameter for rate of change\n",
    "\n",
    "# Extract column names, ensuring \"SN\" is excluded\n",
    "columns = [col for col in pivot_df.columns if col != \"SN\"]\n",
    "\n",
    "# Function to calculate Age of Incorrect Information (AoII) at the sink\n",
    "def calculate_aoii_sink(current_time, last_received_time, last_rate_of_change):\n",
    "    return abs((current_time - last_received_time) * last_rate_of_change)\n",
    "\n",
    "# Helper function to update state using dEWMA\n",
    "def update_node_state_dewma(measured_value, last_state_value, last_rate_of_change, delta_t, beta_1, beta_2):\n",
    "    x1 = beta_1 * measured_value + (1 - beta_1) * (last_state_value + last_rate_of_change * delta_t)\n",
    "    x2 = beta_2 * (x1 - last_state_value) / delta_t + (1 - beta_2) * last_rate_of_change\n",
    "    return x1, x2\n",
    "\n",
    "# Function to extract numeric node ID from column names\n",
    "def extract_node_id(col_name):\n",
    "    digits = ''.join(filter(str.isdigit, col_name))\n",
    "    return int(digits) if digits else None\n",
    "\n",
    "# Normalize a value using fixed min-max range for each category\n",
    "def normalize_value(value, node_id):\n",
    "    # Fixed ranges per category\n",
    "    if 1 <= node_id <= 5:  # Category A\n",
    "        min_val = 15\n",
    "        max_val = 25\n",
    "    elif 6 <= node_id <= 10:  # Category B\n",
    "        min_val = 75\n",
    "        max_val = 125\n",
    "    else:\n",
    "        # Default fallback\n",
    "        return value / 100.0\n",
    "    \n",
    "    # Standard min-max normalization with clipping\n",
    "    normalized = (value - min_val) / (max_val - min_val)\n",
    "    normalized = max(0, min(1, normalized))\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "# Run normalized simulation\n",
    "def run_normalized_simulation():\n",
    "    # Initialize tracking variables\n",
    "    last_update_times = {col: 0 for col in columns}\n",
    "    state_node = {}\n",
    "    for col in columns:\n",
    "        node_id = extract_node_id(col)\n",
    "        if node_id is not None:\n",
    "            # Get initial value from dataset or use default\n",
    "            initial_val = pivot_df.loc[0, col] if not pd.isna(pivot_df.loc[0, col]) else initial_value\n",
    "            normalized_val = normalize_value(initial_val, node_id)\n",
    "            state_node[col] = np.array([normalized_val, 0.1])\n",
    "        else:\n",
    "            state_node[col] = np.array([0.5, 0.1])\n",
    "    \n",
    "    # Track category counts\n",
    "    category_counts = {'Category A': 0, 'Category B': 0}\n",
    "\n",
    "    for t in range(len(pivot_df)):\n",
    "        # Progress indicator (every 5000 steps)\n",
    "        if t % 5000 == 0:\n",
    "            print(f\"Step {t}/{len(pivot_df)}...\")\n",
    "            \n",
    "        # Compute Whittle indices for each node\n",
    "        whittle_indices = {}\n",
    "        for col in columns:\n",
    "            node_id = extract_node_id(col)\n",
    "            if node_id is None:\n",
    "                continue\n",
    "                \n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "            measured_value = pivot_df.loc[t, col]\n",
    "            \n",
    "            # Skip if value is NaN\n",
    "            if pd.isna(measured_value):\n",
    "                continue\n",
    "\n",
    "            # Calculate AoII in normalized space\n",
    "            current_aoii = calculate_aoii_sink(t, last_update_times[col], last_rate_of_change)\n",
    "            future_aoii_passive = calculate_aoii_sink(t+1, last_update_times[col], last_rate_of_change)\n",
    "            future_aoii_active = 0  # AoII resets to 0 if polled\n",
    "\n",
    "            # Whittle index calculations\n",
    "            q_passive = current_aoii + future_aoii_passive\n",
    "            q_active = current_aoii + future_aoii_active + aoii_penalty\n",
    "            whittle_indices[col] = q_passive - q_active\n",
    "\n",
    "        # Select nodes to poll based on Whittle indices\n",
    "        nodes_to_poll = [col for col in whittle_indices if whittle_indices[col] >= 0]\n",
    "        if len(nodes_to_poll) > M:\n",
    "            nodes_to_poll = sorted(nodes_to_poll, key=whittle_indices.get, reverse=True)[:M]\n",
    "            \n",
    "        # Poll selected nodes and update states\n",
    "        for col in nodes_to_poll:\n",
    "            measured_value = pivot_df.loc[t, col]\n",
    "            \n",
    "            # Skip if value is NaN\n",
    "            if pd.isna(measured_value):\n",
    "                continue\n",
    "            \n",
    "            node_id = extract_node_id(col)\n",
    "            if node_id is None:\n",
    "                continue\n",
    "                \n",
    "            # Normalize the measured value\n",
    "            normalized_value = normalize_value(measured_value, node_id)\n",
    "            \n",
    "            # Get last state in normalized space\n",
    "            last_state_value, last_rate_of_change = state_node[col]\n",
    "            \n",
    "            # Calculate time since last update (min 1 to avoid division by zero)\n",
    "            delta_t_dynamic = max(1, t - last_update_times[col])\n",
    "            \n",
    "            # Update state using dEWMA with normalized measured value\n",
    "            state_node[col] = update_node_state_dewma(\n",
    "                normalized_value, last_state_value, last_rate_of_change, \n",
    "                delta_t_dynamic, beta_1, beta_2\n",
    "            )\n",
    "            \n",
    "            last_update_times[col] = t\n",
    "\n",
    "            # Categorize based on node ID\n",
    "            if 1 <= node_id <= 5:\n",
    "                category_counts['Category A'] += 1\n",
    "            elif 6 <= node_id <= 10:\n",
    "                category_counts['Category B'] += 1\n",
    "\n",
    "    return category_counts\n",
    "\n",
    "# Run the simulation and print results\n",
    "print(\"Running normalized simulation...\")\n",
    "category_counts = run_normalized_simulation()\n",
    "\n",
    "print(\"\\nRESULTS:\")\n",
    "print(f\"Category A: {category_counts['Category A']} polls\")\n",
    "print(f\"Category B: {category_counts['Category B']} polls\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
